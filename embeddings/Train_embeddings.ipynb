{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install DGL-KE\n",
    "Before training the model, we need to install dgl and dgl-ke packages as well as other dependencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/xiongbo/anaconda3/envs/fea/lib/python3.7/site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy in /home/xiongbo/anaconda3/envs/fea/lib/python3.7/site-packages (from torch) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /home/xiongbo/anaconda3/envs/fea/lib/python3.7/site-packages (from torch) (3.7.4.3)\n",
      "Collecting dgl==0.4.3post2\n",
      "  Downloading dgl-0.4.3.post2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /home/xiongbo/anaconda3/envs/fea/lib/python3.7/site-packages (from dgl==0.4.3post2) (1.19.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/xiongbo/anaconda3/envs/fea/lib/python3.7/site-packages (from dgl==0.4.3post2) (1.4.1)\n",
      "Requirement already satisfied: networkx>=2.1 in /home/xiongbo/anaconda3/envs/fea/lib/python3.7/site-packages (from dgl==0.4.3post2) (2.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/xiongbo/anaconda3/envs/fea/lib/python3.7/site-packages (from dgl==0.4.3post2) (2.25.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/xiongbo/anaconda3/envs/fea/lib/python3.7/site-packages (from networkx>=2.1->dgl==0.4.3post2) (4.4.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/xiongbo/anaconda3/envs/fea/lib/python3.7/site-packages (from requests>=2.19.0->dgl==0.4.3post2) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/xiongbo/anaconda3/envs/fea/lib/python3.7/site-packages (from requests>=2.19.0->dgl==0.4.3post2) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/xiongbo/anaconda3/envs/fea/lib/python3.7/site-packages (from requests>=2.19.0->dgl==0.4.3post2) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/xiongbo/anaconda3/envs/fea/lib/python3.7/site-packages (from requests>=2.19.0->dgl==0.4.3post2) (4.0.0)\n",
      "Installing collected packages: dgl\n",
      "Successfully installed dgl-0.4.3.post2\n",
      "Collecting dglke\n",
      "  Downloading dglke-0.1.2-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 3.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/xiongbo/anaconda3/envs/fea/lib/python3.7/site-packages (from dglke) (1.19.5)\n",
      "Requirement already satisfied: setuptools in /home/xiongbo/anaconda3/envs/fea/lib/python3.7/site-packages (from dglke) (52.0.0.post20210125)\n",
      "Installing collected packages: dglke\n",
      "Successfully installed dglke-0.1.2\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install torch\n",
    "# !pip3 install dgl==0.4.3post2 \n",
    "# !pip3 install dglke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train/valid/test set\n",
    "Before training, we need to split the original drkg into train/valid/test set with a 9:0.5:0.5 manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2250196"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(1, './utils')\n",
    "from utils import download_and_extract\n",
    "download_and_extract()\n",
    "drkg_file = './hetionet/hetionet.tsv'\n",
    "\n",
    "df = pd.read_csv(drkg_file, sep=\",\")\n",
    "triples = df.values.tolist()\n",
    "\n",
    "len(triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get 5,869,293 triples, now we will split them into three files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2250196"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_triples = len(triples)\n",
    "num_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please make sure the output directory exist.\n",
    "seed = np.arange(num_triples)\n",
    "np.random.shuffle(seed)\n",
    "\n",
    "train_cnt = int(num_triples * 0.9)\n",
    "valid_cnt = int(num_triples * 0.05)\n",
    "train_set = seed[:train_cnt]\n",
    "train_set = train_set.tolist()\n",
    "valid_set = seed[train_cnt:train_cnt+valid_cnt].tolist()\n",
    "test_set = seed[train_cnt+valid_cnt:].tolist()\n",
    "\n",
    "with open(\"./hetionet/hetionet_train.tsv\", 'w+') as f:\n",
    "    for idx in train_set:\n",
    "        f.writelines(\"{}\\t{}\\t{}\\n\".format(triples[idx][0], triples[idx][1], triples[idx][2]))\n",
    "        \n",
    "with open(\"./hetionet/hetionet_valid.tsv\", 'w+') as f:\n",
    "    for idx in valid_set:\n",
    "        f.writelines(\"{}\\t{}\\t{}\\n\".format(triples[idx][0], triples[idx][1], triples[idx][2]))\n",
    "\n",
    "with open(\"./hetionet/hetionet_test.tsv\", 'w+') as f:\n",
    "    for idx in test_set:\n",
    "        f.writelines(\"{}\\t{}\\t{}\\n\".format(triples[idx][0], triples[idx][1], triples[idx][2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./yago/yago_train.tsv\", 'w+') as f:\n",
    "#     for idx in train_set:\n",
    "#         f.writelines(\"{}\\t{}\\t{}\\n\".format(triples[idx][0], triples[idx][1], triples[idx][2]))\n",
    "        \n",
    "# with open(\"./yago/yago_valid.tsv\", 'w+') as f:\n",
    "#     for idx in valid_set:\n",
    "#         f.writelines(\"{}\\t{}\\t{}\\n\".format(triples[idx][0], triples[idx][1], triples[idx][2]))\n",
    "\n",
    "# with open(\"./yago/yago_test.tsv\", 'w+') as f:\n",
    "#     for idx in test_set:\n",
    "#         f.writelines(\"{}\\t{}\\t{}\\n\".format(triples[idx][0], triples[idx][1], triples[idx][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training TransE_l2 model\n",
    "We can training the TransE_l2 model by simplying using DGL-KE command line. For more information about using DGL-KE please refer to https://github.com/awslabs/dgl-ke.\n",
    "\n",
    "Here we train the model using 8 GPUs on an AWS p3.16xlarge instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Reading train triples....\n",
      "Finished. Read 2025176 train triples.\n",
      "Reading valid triples....\n",
      "Finished. Read 112509 valid triples.\n",
      "Reading test triples....\n",
      "Finished. Read 112511 test triples.\n",
      "|Train|: 2025176\n",
      "random partition 2025176 edges into 8 parts\n",
      "part 0 has 253147 edges\n",
      "part 1 has 253147 edges\n",
      "part 2 has 253147 edges\n",
      "part 3 has 253147 edges\n",
      "part 4 has 253147 edges\n",
      "part 5 has 253147 edges\n",
      "part 6 has 253147 edges\n",
      "part 7 has 253147 edges\n",
      "/workspace/anaconda3/envs/bio/lib/python3.7/site-packages/dgl/base.py:25: UserWarning: multigraph will be deprecated.DGL will treat all graphs as multigraph in the future.\n",
      "  warnings.warn(msg, warn_type)\n",
      "|valid|: 112509\n",
      "|test|: 112511\n",
      "Total initialize time 5.560 seconds\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/anaconda3/envs/bio/bin/dglke_train\", line 8, in <module>\n",
      "Process Process-1:1:\n",
      "Process Process-3:1:\n",
      "Process Process-4:1:\n",
      "Process Process-2:1:\n",
      "    sys.exit(main())\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/site-packages/dglke/train.py\", line 281, in main\n",
      "    proc.join()\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/site-packages/dglke/models/pytorch/tensor_models.py\", line 119, in decorated_function\n",
      "    result, exception, trace = queue.get()\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/site-packages/dglke/models/pytorch/tensor_models.py\", line 119, in decorated_function\n",
      "    result, exception, trace = queue.get()\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/site-packages/dglke/models/pytorch/tensor_models.py\", line 119, in decorated_function\n",
      "    result, exception, trace = queue.get()\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/site-packages/dglke/models/pytorch/tensor_models.py\", line 119, in decorated_function\n",
      "    result, exception, trace = queue.get()\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/workspace/anaconda3/envs/bio/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!DGLBACKEND=pytorch dglke_train --dataset hetionet --data_path ./hetionet --data_files hetionet_train.tsv hetionet_valid.tsv hetionet_test.tsv --format 'raw_udd_hrt' --model_name TransE_l2 --batch_size 2048 \\\n",
    "--neg_sample_size 256 --hidden_dim 200 --gamma 12.0 --lr 0.1 --max_step 100000 --log_interval 1000 --batch_size_eval 16 -adv --regularization_coef 1.00E-07 --test --num_thread 1 --gpu 0 1 2 3 --num_proc 8 --neg_sample_size_eval 10000 --async_update\n",
    "\n",
    "!DGLBACKEND=pytorch dglke_train --dataset hetionet --data_path ./hetionet --data_files hetionet_train.tsv hetionet_valid.tsv hetionet_test.tsv --format 'raw_udd_hrt' --model_name RotatE --batch_size 512 \\\n",
    "--neg_sample_size 128 --hidden_dim 200 --gamma 12.0 --lr 0.1 --max_step 100000 --log_interval 1000 --batch_size_eval 16 -adv --regularization_coef 1.00E-07 --test --num_thread 1 --gpu 0 1 2 3 --num_proc 8 --neg_sample_size_eval 10000 --async_update\n",
    "\n",
    "\n",
    "# !DGLBACKEND=pytorch dglke_train --dataset yago --data_path ./yago --data_files yago_train.tsv yago_valid.tsv yago_test.tsv --format 'raw_udd_hrt' --model_name TransE_l2 --batch_size 2048 \\\n",
    "# --neg_sample_size 256 --hidden_dim 100 --gamma 12.0 --lr 0.1 --max_step 100000 --log_interval 1000 --batch_size_eval 16 -adv --regularization_coef 1.00E-07 --test --num_thread 1 --gpu 0 1 2 3 --num_proc 8 --neg_sample_size_eval 10000 --async_update\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Entity and Relation Embeddings\n",
    "The resulting model, i.e., the entity and relation embeddings can be found under ./ckpts. (Please refer to the first line of the training log for the specific location.)\n",
    "\n",
    "The overall process will generate 4 important files:\n",
    "\n",
    "  - Entity embedding: ./ckpts/<model\\_name>_<dataset\\_name>_<run_\\id>/xxx\\_entity.npy\n",
    "  - Relation embedding: ./ckpts/<model\\_name>_<dataset\\_name>_<run\\_id>/xxx\\_relation.npy\n",
    "  - The entity id mapping, formated in <entity\\_name> <entity\\_id> pair: <data\\_path>/entities.tsv\n",
    "  - The relation id mapping, formated in <relation\\_name> <relation\\_id> pair: <data\\_path>/relations.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./ckpts/TransE_l2_DRKG_0/\n",
    "!ls ./train/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Glance of the Entity and Relation Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_emb = np.load('./ckpts/TransE_l2_DRKG_0/DRKG_TransE_l2_entity.npy')\n",
    "relation_emb = np.load('./ckpts/TransE_l2_DRKG_0/DRKG_TransE_l2_relation.npy')\n",
    "\n",
    "print(node_emb.shape)\n",
    "print(relation_emb.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
